{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25284de",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9826ef3d",
   "metadata": {},
   "source": [
    "## Approach\n",
    "The goal of classification is to assign a given data point to one of a set of possible classes. In this case, we have measurements of a particle that we're assigning to be either stone microdebitage or soil."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3624ac29",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers\n",
    "Although we want to design a model that is accurate. High accuracy is not an adequate metric, especially in the case of imbalanced classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8512092",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "A matrix of correctly classified and misclassified observations is helpful in considering the strengths and weaknesses of a model holistically. True positives and true negatives are correct. False positives and false negatives are incorrect.\n",
    "\n",
    "\n",
    "| Actual / Predicted | Positive | Negative |\n",
    "| ------------------ | -------- | -------- |\n",
    "| **Positive**       |    TP    |    FN    |\n",
    "| **Negative**       |    FP    |    TN    | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "210cc219",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F1\n",
    "- Precision is the actual positive proportion of observations that were predicted positive. This measure penalizes false positives.\n",
    "- Recall (sensitivity) is the percentage of total positive cases captured. This measure penalizes false negatives.\n",
    "- Where precision and recall are both important, the F1 score can be used, which is their harmonic mean."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22542172",
   "metadata": {},
   "source": [
    "### ROC and AUC\n",
    "A visualization method, the receiver operating characteristic (ROC) curve plots the true positive rate versus the false positive rate for various threholds. The area under the curve (AUC) measures how well the classifier separates the classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b344390",
   "metadata": {},
   "source": [
    "### Implemented Classifiers\n",
    "- Logistic Regression `41-log-regression.ipynp`\n",
    "- Gaussian Naive Bayes `42-naive-bayes.ipynp`\n",
    "- Support Vector Machine `43-support-vector-machine.ipynp`\n",
    "- Decision Tree `44-decision-tree.ipynp`\n",
    "- Random Forest `45-random-forest.ipynp`\n",
    "- Extra Trees `46-extra-trees.ipynp`\n",
    "\n",
    "### Other Possible Classifiers\n",
    "- Linear Discriminant Analysis\n",
    "- Quadratic Discriminant Analysis\n",
    "- K-Nearest Neighbors\n",
    "- Multi-layer Perceptron\n",
    "- AdaBoost \n",
    "- GradientBoosting\n",
    "- Bernoulli Naive Bayes\n",
    "- Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a392d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
